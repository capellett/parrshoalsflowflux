---
title: "A Comparison of Alternative Flow Fluctuation Metrics for Parr Shoals Reservoir Releases"
author: "CA Pellett"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{intro}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

Similar to many reservoirs in SC and globally, the streamflow downstream of the Parr Shoals dam often vary widely from hour to hour in an un-natural pattern caused by operations at the combined Parr Shoals-Monticello hydro and nuclear power projects. These artificial flow fluctuations can have detrimental impacts on the aquatic community, particularly during fish spawning periods. Recently, the dam operators have been demonstrating significant improvements in reducing these artificial flow fluctuations.  

I have attended meetings related to the FERC re-licensing of Parr Shoals and Monticello reservoirs for most of my career at SC DNR. I started in 2015, some time after the relicensing process had begun for this project, which followed multiple other relicensing projects for other reservoirs in SC. That is to say, there has always been a great deal of experience around the table, and I've learned a lot from participating. My own contributions have been, at most, minor, but the aspects related to the managed reservoir releases of water downstream have always held my interest; this is where my other experience of surface water modelling across the state seems most relevant.

In discussions with stakeholders on both sides of the table, it had seemed, to me, that significant improvements to the flow fluctuations might be unlikely, as there are a number of operational constraints and the costs of retro-fitting appeared astronomical. I have been delighted to see the innovative, cutting-edge, and apparently cost-effective solutions which have been implemented. The Parr Shoals operators have demonstrated significant and profound improvements - reducing the artificial flow fluctuations to provide more stable habitat downstream. With this increased capacity to modulate gate positions in response to varying reservoir levels, I propose that now is a timely opportunity to revisit and refine the metrics by which we evaluate flow-fluctuations. The metrics which have been used have been sufficient to demonstrate the improvements over time. However, as I've noted in previous comments, there are some limitations to those metrics which could confound the analysis. Now that a greater level of capability has been achieved, the AMP committee has an opportunity to fine-tune the metrics, potentially spurring further improvements without further costs. I want to be clear, this is not a critique of past efforts - my proposal of further refinement to the metrics is motivated by the demonstrable success of past efforts by the operators and their consultants.

The objectives of this memo are:
  1. Compile a flow dataset suitable for subsequent analysis.
  2. Develop a couple of alternative metrics to quantify the flow-fluctuations.
  3. Compare the metrics over time and during the spring spawning season.
  
This memo is a reproducible document generated using free and open-source software (R language and packages) and data from the USGS. It can be updated easily, or modified, for example to consider alternative metrics. 

## System Parameters
The following parameters are relevant to analyze the flow fluctuations.

### Spawning Periods
The exact period used for spawning has slipped my mind. For this analysis, I'll say the entire month of March, although I think it was only a couple of weeks.

```{r}
## an integer vector of length 2, 
## julian dates of start and end if spawning period
spawning_period <- c(
  lubridate::yday(lubridate::as_date('2020-03-01')),
  lubridate::yday(lubridate::as_date('2020-03-31')) )
## this gets messed up by leapyear.
## consider using a time-interval or something else from lubridate package.

## if you change the format of the spawning period object, 
## change the function below accordingly:
check_spawning_period <- function(date, spawning_period = spawning_period) {
  date_julian <- lubridate::yday(date)
  date_julian >= spawning_period[1] &
    date_julian <= spawning_period[2]}

```

### Hydro-electric Turbine Outflows
Below 4,800 cfs, all outflows are through the hydro-power turbines. That number will be lower if some turbines are not operational, and higher if the turbine capacity is increased. If the maximum turbine outflow has changed over the period of analysis, then this analysis should be refined to reflect those changes. I think one of the turbines was down for maintenance for a while, reducing the maximum turbine outflow to 3,200 cfs for a time period(?)

### Spill Release Outflows
When outflow is greater than 40,000 cfs, all gates are lowered to prevent damage to the dam.

### Detailed Gate Specifications 
Some more detailed specs on the gate operations could be relevant. The rotational speed of the gates, the number of gates, stage-flow relationships over the top of the gates(?). I don't have details at the moment, and perhaps they aren't necessary.

# Hydrology Data

The USGS maintains stream gages on the major incoming tributaries (Tyger, Enoree, and Broad rivers) to Lake Parr, and another stream gage on the outflow (Broad River at Alston). These datesets cover different time ranges, have different temporal resolutions (e.g. observations every 15 minutes or 1 hour), and may be missing some data. Here the gaged streamflow data is downloaded and combined in to a single dataset.

```{r data-download, eval=F, echo=F}
### This takes a few minutes to run. 
### Install the dataRetrieval package (developed by USGS), if needed.
# install.packages('dataRetrieval')

tyger0 <- dataRetrieval::readNWISuv(
  siteNumbers = '02160105', parameterCd = c('00060', '00065'))

enoree0 <- dataRetrieval::readNWISuv(
  siteNumbers = '02160700', parameterCd = c('00060', '00065'))

broad0 <- dataRetrieval::readNWISuv(
  siteNumbers = '02156500', parameterCd = c('00060', '00065'))

alston0 <- dataRetrieval::readNWISuv(
  siteNumbers = '02161000', parameterCd = c('00060', '00065'))

parr0 <- dataRetrieval::readNWISuv(
  siteNumbers = '02160990', parameterCd = '00065')


## if the data-raw folder doesn't exist, create it.
saveRDS(tyger0, '../data-raw/tyger0.rds')
saveRDS(enoree0, '../data-raw/enoree0.rds')
saveRDS(broad0, '../data-raw/broad0.rds')
saveRDS(alston0, '../data-raw/alston0.rds')
saveRDS(parr0, '../data-raw/parr0.rds')
```

### Gaged Inflows
```{r}
inflow_prep_function <- function(x) {
  x |>
  dplyr::arrange(dateTime) |>
  dplyr::mutate(dateTime_lag1 = dplyr::lag(dateTime),
                time_interval = lubridate::interval(
                  dateTime_lag1, dateTime) |>
                  lubridate::as.duration())
}

```

#### Tyger River Near Delta
USGS Gage No. 02160105 drains 759 sqmi.
```{r}
tyger0 <- readRDS('../data-raw/tyger0.rds') |>
  inflow_prep_function()
```

#### Enoree River at Whitmire
USGS Gage No. 02160700 drains 444 sqmi.
```{r}
enoree0 <- readRDS('../data-raw/enoree0.rds') |>
  inflow_prep_function()
```

#### Broad River at Carlisle
USGS Gage No. 02156500 drains 2,780 sqmi.
```{r}
broad0 <- readRDS('../data-raw/broad0.rds') |>
  inflow_prep_function()
```

### Gaged Outflow 
#### Broad River at Jenkinsville
USGS Gage No. 02160991 drains 4,750 sqmi. This gage was active before the reservoir was constructed. Could be relevant, but I'm not sure about it.

#### Broad River at Alston
USGS Gage No. 02160000 drains 4,790 sqmi. Located just a bit downriver of the Parr dam, this gage is representative of the outflows from the reservoir. I guess it drains about 40 more square miles (4790 - 4750?) than the impounded watershed.

```{r}
alston0 <- readRDS('../data-raw/alston0.rds') |>
  inflow_prep_function()
```


### Combined Flow Dataset
Total inflow can be estimated by combining the three inflow datasets. A simple sum has been used. Perhaps that can be refined. Lets review the data availability from the four stream gages first.

```{r}
flows0 <- dplyr::bind_rows(
  Broad=broad0, Enoree=enoree0, Tyger=tyger0, Alston=alston0, .id = 'gage')
```

#### Timestep Assessment
The different stream gage datasets may have different timesteps over time. Let's assess that graphically. First, I calculate the time interval between each observation and the prior observation at that gage site.

```{r}
## y = time_interval x = date
# time_interval_plot2 <- function(x) {x |>
flows0 |>
  ggplot2::ggplot(
    ggplot2::aes(x=dateTime, y=time_interval)) +
  ggplot2::geom_point(size=0.1) +
  ggplot2::scale_y_log10(
    breaks=c(60, 900, 3600, 86400, 604800, 2592000,
            31536000, 315360000, 3153600000),
    minor_breaks = NULL,
    labels=c("1m", '15m', "1h","1d","7d","30d",
            "1y", "10y", "100y")) +
  ggplot2::theme_bw() +
  ggplot2::facet_wrap('gage', ncol=1)
# }
```
The graph above shows that the gages generally have hourly data available starting after 1985 and 15-minute data starting around 2020. It looks like the Alston gage has 15 minute data going way back. That could be useful to show improvement over time, but I'm not going to look that far back at this point. There are some time intervals of over a week.

After combining the flow data in to a single table, with a row for each timestep and a column for each gage location, I'm going to remove rows which are missing data for any of the 4 gage locations (3 inflow gages). We might do better by trying to interpolate missing data, instead of simply removing it. But I think there is more than enough complete data in the sample, and interpolation could introduce error. 

```{r}
flows1 <- flows0 |>
  dplyr::select(gage, dateTime, flow = X_00060_00000) |>
  tidyr::pivot_wider(names_from = gage, values_from=flow) |>
  dplyr::filter(
    !is.na(Broad) & !is.na(Enoree) & 
      !is.na(Tyger) & !is.na(Alston)) |>
  inflow_prep_function()
```

```{r combined-time-interval-plot}
flows1 |>
  ggplot2::ggplot(
    ggplot2::aes(x=dateTime, y=time_interval)) +
  ggplot2::geom_point(size=0.1) +
  ggplot2::scale_y_log10(
    breaks=c(60, 900, 3600, 86400, 604800, 2592000,
            31536000, 315360000, 3153600000),
    minor_breaks = NULL,
    labels=c("1m", '15m', "1h","1d","7d","30d",
            "1y", "10y", "100y")) +
  ggplot2::theme_bw()

```
Here is a plot of the time-intervals between complete observations (observation events with data for all 4 gage sites). Apparently, there is very little missing data since the 15-minute observations began for all gages. Since 2020, there are no data gaps over 2 hours.

#### Missing data assessment
```{r combined-missing-data-plot}
flows2 <- flows1 |>
  dplyr::mutate(epoch = dplyr::if_else(
    dateTime < lubridate::as_datetime('2019-12-05 00:00:00'),
    '1hr', '15min'))

flow_test <- flows2 |>
  dplyr::mutate(
    denominator = dplyr::if_else(epoch == '1hr', 24, 96),
    day = lubridate::as_date(dateTime)) |>
  dplyr::group_by(epoch, day, denominator) |>
  dplyr::summarise(n = dplyr::n()) |>
  dplyr::ungroup() |>
  dplyr::mutate(missingObs = denominator - n)

range(flow_test$missingObs)

flow_test |>
  ggplot2::ggplot(
    ggplot2::aes(x=day, y=missingObs, color=epoch)) +
  ggplot2::geom_point(size=0.1) +
  ggplot2::theme_bw()
```
Since the 15-minute observations began, there have been no more than 10 missing observations in a single day. (The high point at the end of the graph is the day the data was downloaded, not a complete day of observations.)

```{r}
flow_test |>
  dplyr::filter(missingObs > 0) |>
  dplyr::mutate(year = lubridate::year(day)) |>
  dplyr::group_by(year) |>
  dplyr::summarise(`number of days with missing data`=dplyr::n()) |>
  dplyr::arrange(dplyr::desc(year))
```

## Data Sampling

For this analysis, I'll stick to the 15-minute data. I'll also label the observations according to flow flow at Alston (between 4,800 and 40,000 cfs, "Gate operation"; "Turbines only" if lower; "Spill" if higher).
```{r}
flows3 <- flows2 |>
  dplyr::filter(epoch == '15min') |>
  dplyr::mutate(outflow_type = dplyr::case_when(
    Alston < 4800 ~ 'Turbines only',
    Alston > 40000 ~ 'Spill',
    .default = 'Gate operation')) |>
  dplyr::select(-epoch, -dateTime_lag1)
```

```{r}
flows3 |>
  tidyr::pivot_longer(Broad:Alston) |>
  ggplot2::ggplot(
    ggplot2::aes(x=dateTime, y=value, group=name,
                 # alpha=outflow_type, 
                 color=name)) +
  ggplot2::geom_line() +
  ggplot2::theme_bw() +
  ggplot2::scale_y_log10(
    name = 'cfs', labels = scales::comma_format())
```
The Broad (at Carlisle) gage has nearly as much flow as the Alston gage (on a logarithmic scale, anyway), but this graph shows that the Alston gage has a lot more flow fluctuation in the gate operation range (4,800 to 40,000 cfs). I think I can see the difference, in 2020, when one of the turbines was not operational, and flow fluctuations affected flows lower than 4,800 cfs.

# Unimpaired Outflows

The inflow data can be used to estimate "unimpaired" outflows, that is, what the outflows might have been in the absence of the Parr Shoals-Monticello projects. Simply adding up the inflows is a good, simple, method, which might be refined by prorating the gaged inflows to account for ungauged area, and introducing a time lag or delay to account for the distance between the inflow gages and the outflow gage. Let's see if we can use the data to derive empirical estimates for area proration factors and lag times.

## Ungaged Inflows
There are some ungaged inflows both upstream and downstream of the dam. The total watershed area of the inflow gages is 759 + 444 + 2,780 = 3,983 square miles.

4750 - 3983 = 767 sqmi ungaged inflow area (upstream of the dam).
4790 - 4750 = 40 sqmi ungaged outflow area (downstream of the dam).

3983 / 4790 = 83% of watershed of the Alston gage is included in the inflow gage subwatersheds.

4790 / 3983 = 1.202611 proration factor. (Multiply the total gauged inflows by the proration factor to account for ungauged areas upstream of the Alston gage.) 

The proration factor, roughly 20%, is calculated as a ratio of watershed and subwatershed areas. Based on the drainage areas, we could assume that the flow at Alston will be about 20% greater than the sum of the inflow gages. We can also use an empirical method to calculate the proration factor.

```{r}
drainage_areas <- tibble::tribble(
  ~gage, ~sqmi,
  'Tyger', 759,
  'Enoree', 444,
  'Broad', 2780,
  'Inflow', 4790,
  'Alston', 4790)

flows4 <- flows3 |>
   dplyr::mutate(Inflow = Broad+Enoree+Tyger)
  
flows4 |>  
   dplyr::summarise(
     dplyr::across(c(Broad, Enoree, Tyger, Alston, Inflow),
                   mean)) |>
  dplyr::mutate(
    dplyr::across(
      c(Broad, Enoree, Tyger, Inflow),
    function(x) x/Alston)) |>
  dplyr::select(-Alston) |>
  tidyr::pivot_longer(cols=Broad:Inflow,
                      names_to = 'gage',
                      values_to = 'Percent of outflow') # |>
  # dplyr::left_join(drainage_areas, 'gage')
```

In a simpler world, the gaged Inflows would equal 83% of the outflows, instead they equal 87% (in this sample of observations). Whereas the watershed areas suggest that outflows would be about 20% more than the gaged inflows, they are empirically only about 15% more - this makes sense because the gaged inflow watersheds include areas of the upper piedmont and blue ridge regions which typically recieve more rainfall than the middle/lower piedmont, where the ungaged inflow area is.

## Lag Times

We expect that it will take some time for water to travel from the inflow gages to the outflow gage. This is called flow routing, and a simple way to account for it is to introduce a delay to represent the travel time from upstream to downstream.

Here, I'll develop an estimate of lag from the total of the inflows. This could be refined by estimating lag times separately for each inflow gage.

```{r}
library(ggplot2)
library(ggpmisc)
```

I'll start by plotting the total gauged inflow against the outflows at Alston. 
```{r}
lag_calibration_plot <- function(data) {
  data |>
   ggplot2::ggplot(
      ggplot2::aes(x=Inflow, y=Alston)) +
    ggplot2::geom_point(alpha=0.1) +
    ggpmisc::stat_poly_line() +
    ggpmisc::stat_poly_eq(ggpmisc::use_label(c("eq", "R2"))) +
    ggplot2::theme_bw() # +
    # ggplot2::facet_wrap('outflow_type', scales='free', ncol=1)
}

flows4 |>
  lag_calibration_plot()
```
Reasonably good correlation. If it were a perfect correlation, there wouldn't be anything to talk about regarding flow fluctuations. Let's see if there is a better correlation when lag times are applied to the gaged inflows. 

```{r warning=F}
for(i in c(1,32,45)) {
  print(
    flows4 |>
      dplyr::mutate(Inflow = dplyr::lag(Inflow, i)) |>
      lag_calibration_plot() +
      ggplot2::ggtitle(paste0("Lag ", i, " timesteps")) )
}
```
Each timestep is 15 minutes, and as I applied lag times of various timesteps, I noticed marginal improvements in the regression equation - outflows match lagged inflows better than the raw inflow data. 

I reviewed all of the plots and equations for lag times from 1 to 45 timesteps. The best R^2 and regression equations come from lags ranging from 31 to 34 timesteps. Thats 7hr45min to 8.5hrs. That seems like a long time. Is that correct, or is there something wrong with my analysis? I expected it to be less time. We might want to compare this with the average water velocity at the gage locations to see if it makes sense.

It might be preferable to set the Y-intercept of the regression line to zero. Also, the lag time for each inflow gage could be estimated separately. This analysis could be developed further, but it seems to indicate that there is a lag time of around 8 hours from the inflow gages to the outflow gage. This seems unlikely, the lag time is probably less than that, and the analysis above is probably confounded by the characteristics of the hydrographs (i.e., the falling limb has a lower slope than the rising limb). 

## Unimpaired outflow conclusions

These results indicate that the gaged inflows could be scaled up 15-20% and delayed by 7.75-8.5 hours to better represent "natural" flows at Alston. For subsequent analysis in this memo, the unimpaired outflows are calculated from the gaged inflows scaled up by 15% and delayed by 8 hours. Further refinement of the lag time estimate is warranted if these methods are to be used for monitoring and evaluation.

```{r}
## add rows for all missing dateTimes before calculating the lag.
missing_observations <- tibble::tibble(
  dateTime = seq(
    from = min(flows4$dateTime),
    to = max(flows4$dateTime),
    by = '15 min') ) |>
  dplyr::anti_join(flows4, 'dateTime')
```

```{r}
flows <- flows4 |>
  dplyr::bind_rows(missing_observations) |>
  dplyr::arrange(dateTime) |>
  dplyr::mutate(Unimpaired_outflow = dplyr::lag(Inflow, 32)*1.15) |>
  dplyr::filter(!is.na(Unimpaired_outflow))

usethis::use_data(flows, overwrite=T)
```

# Flow Variability

Alternatively, it is possible to evaluate the flow fluctuations at the Alston gage without making direct comparisons to a synthetic unimpaired streamflow dataset. Here we will derive a new variable, `delta`, which is the instantaneous flow minus the value of the previous observation. That is to say, for each observation of flow at time "t", cfs_t, the delta is calculated by subtracting the previous observed value: delta = cfs_t - cfs_(t-1).

Let's consider only the 15 minute data, and look at the flow fluctuations at the different gauges and for the synthetic inflow.
```{r}
flux0 <- flows |>
  dplyr::arrange(dateTime) |>
  dplyr::mutate(
    dplyr::across(
      c(Broad, Enoree, Tyger, Alston, Inflow), 
      function(x) {x - dplyr::lag(x)},
      .names="{.col}_delta")) |>
  dplyr::filter(time_interval == 900)

flux1 <- flux0 |>
  dplyr::select(
    dateTime, outflow_type, dplyr::everything(),
    -time_interval, -Unimpaired_outflow) |>
  dplyr::rename(Broad_flow=Broad,
                Enoree_flow=Enoree,
                Tyger_flow=Tyger,
                Alston_flow=Alston,
                Inflow_flow=Inflow) |>
  tidyr::pivot_longer(
    cols=3:12,
    names_to = c('gage', 'name'),
    names_sep='_') |>
  tidyr::pivot_wider() |>
  dplyr::mutate(limb = dplyr::if_else(
    delta>0, 'rising', 'falling'),
    delta = abs(delta)) |>
  dplyr::left_join(drainage_areas, 'gage')
  
```

```{r eval=F}
flux <- flux1 
usethis::use_data(flux, overwrite=T)
```

## Delta in terms of cfs / sqmi 

To make comparisons among the different gages, here I'll divide the delta cfs by the square miles of drainage area.

```{r warning=FALSE}
flux1 |>
  dplyr::filter(outflow_type == 'Gate operation') |>
  ggplot2::ggplot(
    ggplot2::aes(x=(delta/sqmi))) +
  ggplot2::geom_histogram() +
  # ggplot2::scale_y_log10() +
  ggplot2::scale_x_log10(
    breaks=c(0.001, 0.01, 0.1, 1),
    labels=c(0.001, 0.01, 0.1, 1)) +
  ggplot2::facet_wrap('gage') +
  ggplot2::theme_bw()
```

This plot shows the count of observations, for each gage, for different values of flow fluctuations, measured in terms of the change in flow (cfs_t1 - cfs_t0) divided by the drainage area (sqmi). This plot includes only flows classified as Gate operations (between 4,800 and 40,000 cfs at the Alston gage).

Looking at the inflow gages and the synthetic inflow data, the natural rate of change for streamflow is very rarely any greater than 0.1 cfs / sqmi / 15 minutes. In contrast, many of the observations at the Alston gage include flow fluctuations of greater than 0.1 cfs/sqmi/15min, which is equivalent to about 480 cfs / 15 minutes at the Alston gage.

## Delta in terms of %

Here, let's look at the flow fluctuations as a percentage of the flow (delta/cfs_t). Let's also look at the rising and falling limbs of the hydrograph separately, and at the different outflow types. I'll plot the cumulative frequencies of the Delta (%) for each of the hydrographs.

```{r}
flux |>
  dplyr::mutate(delta_percent = delta/flow) |>
  dplyr::group_by(gage, limb) |>
  dplyr::mutate(
    cumulative_frequency = rank(delta_percent)/dplyr::n()) |>
  ggplot2::ggplot(
    ggplot2::aes(x=cumulative_frequency, y=delta_percent, color=limb)) +
  ggplot2::facet_grid(gage ~ outflow_type) +
  ggplot2::geom_line() +
  ggplot2::scale_x_continuous(limits = c(0.5, NA)) +
  # ggplot2::scale_x_log10(labels=scales::label_percent()) +
  ggplot2::scale_y_log10(labels=scales::label_comma(),
                         limits = c(0.001, NA)) +
  ggplot2::theme_bw()
```
There are several takeaways from this plot. First, the falling limbs of the hydrographs have lower slopes than the rising limbs; that makes sense. This is illustrated by the position of the red lines being consistently underneath the blue lines.

Second, and more pertinent, is that the highest percentage deltas are found at the Alston gage; that is also expected. This is illustrated in the graph, for example by tracking up the 0.75 mark on the X-axis of the first column of plots ("Gate operation"). In the inflow plots, both lines at the 0.7 mark are around 0.01 delta percent; in other words, 70% of observations are no more than 1% different from the previous observation. At the Alston gage, both lines are higher, and they rise higher still. The Alston flows vary by as much as 10% from observation to observation, while the inflow gages hardly ever vary so much.

I expected the biggest differences to be in the "Gate operation" outflows, but similar differences are shown in the "Spill" and "Turbines only" outflows.

## Flow variability conclusions

Based on the graphical analysis above, we could conclude that changes in flow of more than 480 cfs or 5% would be very rare under a natural flow regime, and somewhat common under the historic flow fluctuations. 

# Evaluation of Alternative Metrics

Now that we have refined our estimate of unimpaired outflow and developed a threshold for flow variability, let's re-evaluate the ongoing reductions in flow fluctuations. We will focus on the March spawning season. We will start by comparing three alternative metrics: deviation from total gaged inflow (raw), deviation from synthetic outflow (refined), and variability over time (delta).

```{r}
flows_evaluation <- flows |>
  dplyr::filter(lubridate::month(dateTime) == 3) |>
  dplyr::mutate(Year = lubridate::year(dateTime),
                Deviation_raw = Alston-Inflow,
                Deviation_refined = Alston-Unimpaired_outflow,
                Delta_cfs = Alston - dplyr::lag(Alston),
                Delta_percent = (Alston - dplyr::lag(Alston))/Alston) |>
  dplyr::select(
    dateTime, Alston, Inflow, Unimpaired_outflow, 
    Year, Deviation_raw:Delta_percent) |>
  dplyr::mutate(
    dplyr::across(Deviation_raw:Delta_percent, abs))
```

## Basic Hydrographs

Basic hydrographs offer the most straightforward way to evaluate the flow fluctuations. Here the Alston gage outflows are plotted in red and the inflows (total of the three inflow gages) are plotted in black, for March of each year from 2020 to 2024.

```{r fig.height=6, fig.width=6}
flows_evaluation |>
  ggplot2::ggplot(
    ggplot2::aes(x=dateTime, y=Alston)) +
  ggplot2::geom_line(color='red') +
  ggplot2::geom_line(
    ggplot2::aes(y=Inflow)) +
    # ggplot2::aes(y=Unimpaired_outflow)) +
  ggplot2::scale_y_log10(name='cfs') +
  ggplot2::facet_wrap('Year', ncol=1, scales='free_x') +
  ggplot2::theme_bw()
```
Graphically, the improvements from 2020 seem substantial. 2022 seems to have been a good year, as well as the latter half of March 2024. How can we evaluate reductions in flow fluctuations in a more objective manner? What can we measure to assess performance?

## Tabular Summary 

In the table below summarises the root mean square of different performance metrics for the 15-minute data and the month of March. `Deviation_raw` is the Alston flow minus the total inflow; `Deviation_refined` is the Alston flow minus the unimpaired outflow (total inflow * 1.15, delayed 8 hours); `Delta_cfs` is the change in flow rate (cfs) from observation to observation at the Alston gage; `Delta_percent` is the percentage change from observation to observation at the Alston gage.  

```{r}
flows_evaluation |>
  dplyr::mutate(
    dplyr::across(Deviation_raw:Delta_percent, function(x) x^2)) |>
  dplyr::group_by(Year) |>
  dplyr::summarise(
    dplyr::across(Deviation_raw:Delta_percent, mean, na.rm=T)) |>
  dplyr::mutate(
    dplyr::across(Deviation_raw:Delta_percent, sqrt)) |>
  dplyr::mutate(
    dplyr::across(Deviation_raw:Delta_percent, round, 2))
```
The different performance metrics tell different stories of progress over the years. Hard to say from these results which metric is best suited to evaluate the flow fluctuations. One thing to note is that the deviations calculated from the refined unimpaired outflows tend to be lower than the deviations calculated from the raw inflow data. 

## Detailed Hydrographs

Maybe we can get a better idea by taking a closer look at the data. The plots below show the different calculations of flow fluctuation for every observation during March.

```{r fig.height=6, fig.width=6}

flows_evaluation |>
  dplyr::select(Year, dateTime, Alston, Inflow, Deviation_raw:Delta_percent) |>
  tidyr::pivot_longer(Alston:Delta_percent) |>
  dplyr::mutate(Type = dplyr::case_match(
    name, c('Alston', 'Inflow') ~ 'Flow (cfs)',
    c('Deviation_raw', 'Deviation_refined') ~ 'Deviation (cfs)',
    'Delta_cfs' ~ 'Delta (cfs)',
    'Delta_percent' ~ 'Delta (%)') ) |>
  dplyr::group_by(Year) |>
  dplyr::group_walk(
    function(.x, .y) {
      print(
      .x |>
        ggplot2::ggplot(
          ggplot2::aes(x=dateTime, y=value, group=name, color=name)) +
        ggplot2::geom_line() +
        ggplot2::facet_wrap('Type', scales='free_y', ncol=1) +
        ggplot2::theme_bw() +
        ggplot2::theme(legend.position='bottom') +
        ggplot2::scale_color_manual(
          values = c(
            Alston='red', Inflow='black', Deviation_raw='blue', 
            Deviation_refined='green', Delta_cfs='gray', 
            Delta_percent='gray') ) +
        ggplot2::ggtitle(.y)  ) })

# ggplot2::ggsave('metric_evaluation.png',
#                 width = 6, height = 6)
  
```
A few things stand out to me from these plots. Again, the refined estimate of deviation (using unimpaired outflow) seems to do better than the deviation metric using raw inflow. The unimpaired outflow calculation could likely be improved using a slightly more sophisticated flow routing algorithm than a simple lag time. For example, during the high flow event in late March of 2021, it seems like the outflow hydrograph is a bit wider than the inflow hydrograph - this make sense hydrologically. The translation of upstream flows to downstream flows is not simply a lag in time, but the flow pulses also tend to be moderated (lower peaks and longer-lasting high flows). Getting that right could help clarify the true effects of the flow-fluctuation-reduction efforts.

Another notable result in these plots is the early outliers in the Delta metrics for years 2022 and 2023. The summary results might look a lot different if those outliers were removed. Removing them from the analysis seems warranted as they appear to be erroneous artifacts.

The delta_cfs and deviation (cfs) based metrics might over-penalize for fluctuations at high-flow (for example, late March 2021), while such fluctuations might not be so impactful for aquatic life. Alternatively, the delta_percent based metric might over-penalize for minor fluctuations at low-flows (for example, mid to late March, 2024). 

# Conclusions

It is exciting to see that the Parr Shoals operators can make significant reductions in the flow fluctuations downstream of the Parr dam. Success in this effort was not a foregone conclusion, and it should be celebrated as a real win for all of our water resource stakeholders. It seems that continued improvements are possible, and it may be the case that refining our metrics can faciliate continued success. In this memo, I've implemented a few refinements based on hydrology theory and empirical evidence, and calculated a few different metrics for evaluating flow-fluctuations. 

Scaling up the inflows by 15-20% seems reasonable. If I understand correctly, this is already being done at least in some of the analyses presented previously. Introducing a lag time, or perhaps a more refined method for translating upstream inflows to unimpaired downstream outflows, may also be warranted. 

The observation-delta metrics of flow variability have an advantage of not requiring an estimate of unimpaired outflows. Because there is not much storage capacity in or net withdrawal from Parr Shoals reservoir (compared to the inflows), the outflow will necessarily match inflow at a long enough time-scale. Thus, simply reducing fluctuations in outflow (managing outflows for lower delta values) should result in a more natural streamflow regime. There is inherent uncertainty in all of the flow datasets, so methods which rely on less data could be more robust. Also, timing of flows (in terms of hours or minutes) can be assumed to have negligible ecological impact, but slight changes in timing can have substantial impacts on the inflow-based metrics of flow fluctuations.

More information regarding gate operations and the real-world constraints faced by the reservoir operators is likely relevant to this effort. 



```{r eval=F}
# Parr Reservoir Levels
parr0 <- readRDS('../data-raw/parr0.rds')
```


